(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{227:function(t,s,a){"use strict";a.r(s);var n=a(1),e=Object(n.a)({},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"content"},[t._m(0),t._v(" "),t._m(1),t._v(" "),a("p",[t._v("Creating a serialized representation of an object is useful in situations such as:")]),t._v(" "),t._m(2),t._v(" "),t._m(3),t._v(" "),a("p",[t._v("There are many Python libraries which assist serialization, but they all seem to suffer from the problem that the object’s dictionary returns it’s attributes in random order (that’s a fundamental of a dictionary - it does not guarantee any ordering in iterative access).")]),t._v(" "),a("p",[t._v("Technically, the serialized object works with attributes in any order, but practically many of the above uses benefit from a fixed and consistent ordering - preferably the order that attributes are declared on the class.")]),t._v(" "),t._m(4),t._v(" "),a("p",[t._v("The basis of a solution is to capture the order in which attributes are added to an object, and apply this ordering to the dictionary when it is used for serialization.")]),t._v(" "),a("p",[t._v("Python has a lot of metaclass techniques which allow solving of problems like this which involve the inner workings of objects. These are some of the techniques I investigated.")]),t._v(" "),t._m(5),t._v(" "),t._m(6),t._v(" "),t._m(7),t._v(" "),t._m(8),t._m(9),t._v(" "),a("p",[t._v("Unfortunately, this option interferes with SqlAlchemy, which adds instrumentation for mapping and change tracking behind the scenes. No error message is raised, but unit tests for updating records failed because the SqlAlchemy change tracking did not work with the OrderedDict enhancement.")]),t._v(" "),t._m(10),t._v(" "),t._m(11),t._v(" "),t._m(12),t._v(" "),t._m(13),t._m(14),t._v(" "),t._m(15),t._v(" "),t._m(16),t._v(" "),a("p",[t._v("Arguably, an explicit list of attributes for serialization is the simplest, therefore best considering Python’s maxim of “Explicit is better than implicit”")]),t._v(" "),t._m(17),t._v(" "),t._m(18),a("p",[t._v("The sorted_for_json property is used in the ModelBase class as follows:")]),t._v(" "),t._m(19),t._v(" "),t._m(20),t._m(21),t._v(" "),a("p",[t._v("The downside is that this is not very DRY - when attributes are changed, this list needs to be updated as well. It would be easy to overlook the serialize list when changing the class. A regression test can guard against this:")]),t._v(" "),t._m(22),t._m(23),t._v(" "),a("p",[t._v("Descriptors are a meta-programming objects which allow standard class behaviour to be altered.")]),t._v(" "),t._m(24),t._v(" "),a("p",[t._v("In some ways, this looks closer to the C# way of defining properties.")]),t._v(" "),a("p",[t._v("A Metaclass is then used during class creation to capture the list of attributes and their order by looking for descriptors of type ModelDescriptorBase.")]),t._v(" "),a("p",[t._v("Note, descriptors could be used for other purposes so a specific abstract base class is used for these descriptors.")]),t._v(" "),a("p",[t._v("Defining the model class:")]),t._v(" "),t._m(25),t._v(" "),t._m(26),a("p",[t._v("Recording the attribute ordering:")]),t._v(" "),t._m(27),t._v(" "),t._m(28),a("p",[t._v("Definition of Model descriptors:")]),t._v(" "),t._m(29),t._v(" "),t._m(30),a("MiniMap")],1)},[function(){var t=this.$createElement,s=this._self._c||t;return s("h1",{attrs:{id:"serializing-objects-in-correct-order"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#serializing-objects-in-correct-order","aria-hidden":"true"}},[this._v("#")]),this._v(" Serializing Objects in Correct Order")])},function(){var t=this.$createElement,s=this._self._c||t;return s("h2",{attrs:{id:"overview"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#overview","aria-hidden":"true"}},[this._v("#")]),this._v(" Overview")])},function(){var t=this.$createElement,s=this._self._c||t;return s("ul",[s("li",[this._v("generating data segments for reports, UI displays, logging etc")]),this._v(" "),s("li",[this._v("persisting some state to local disk, e.g. last file processed")]),this._v(" "),s("li",[this._v("creating json documents for a NoSQL database")]),this._v(" "),s("li",[this._v("passing objects across process boundaries")])])},function(){var t=this.$createElement,s=this._self._c||t;return s("h2",{attrs:{id:"the-problem-dictionaries-iterate-in-random-order"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-problem-dictionaries-iterate-in-random-order","aria-hidden":"true"}},[this._v("#")]),this._v(" The Problem - Dictionaries Iterate in Random Order")])},function(){var t=this.$createElement,s=this._self._c||t;return s("h2",{attrs:{id:"the-solution-capturing-attribute-initialisation-order"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-solution-capturing-attribute-initialisation-order","aria-hidden":"true"}},[this._v("#")]),this._v(" The Solution - Capturing Attribute Initialisation Order")])},function(){var t=this.$createElement,s=this._self._c||t;return s("h3",{attrs:{id:"option-1-wrapping-dict-with-an-ordereddict"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#option-1-wrapping-dict-with-an-ordereddict","aria-hidden":"true"}},[this._v("#")]),this._v(" Option 1: Wrapping "),s("strong",[this._v("dict")]),this._v(" with an OrderedDict")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[this._v("One way is to “wrap” the "),s("strong",[this._v("dict")]),this._v(" with an OrderedDict. Overriding the setter and getter class functions makes this possible. (Here, we only need to replace the setter). The code is applied to the Model classes via a mixin class (OrderedNamespace) to the ModelBase class.")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("ordered_namespace.py")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" collections "),a("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OrderedDict\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Model classes inherit from OrderedNamespace")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("OrderedNamespace")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token builtin"}},[t._v("object")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("OrderedNamespace"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n              "),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__setattr__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'_odict'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" OrderedDict"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Setter saves the attribute name in an OrderedDict")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# (which preserves the order the keys are set).")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__setattr__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("hasattr")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'_odict'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v("\n           "),a("span",{attrs:{class:"token operator"}},[t._v("not")]),t._v(" key "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_odict"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_odict"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("key"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("key"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" value\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# The property ordered_dict is used for serialization.")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Current values from the class dict are copied in.")]),t._v("\n    @"),a("span",{attrs:{class:"token builtin"}},[t._v("property")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("ordered_dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" key "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_odict"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_odict"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("key"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("key"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_odict\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Problem with Option 1: Clashes with other libraries using base classes (e.g SqlAlchemy)")])])},function(){var t=this.$createElement,s=this._self._c||t;return s("h3",{attrs:{id:"option-2-finding-dict-order-from-a-mock-object-instantiation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#option-2-finding-dict-order-from-a-mock-object-instantiation","aria-hidden":"true"}},[this._v("#")]),this._v(" Option 2: Finding dict order from a mock object instantiation")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[this._v("This method waits until serialisation time to find the required dictionary ordering. This is nice, because there is no process overhead if the class is never serialised. It does so by mocking the object’s class and overriding "),s("strong",[this._v("setattr")]),this._v(".")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Function: ordered_dict()")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("ordered_dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("not")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("hasattr")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'__dict__'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Attempt a mock instantiation")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# If failed, just use the __dict__ as-is")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("try")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        dict_order "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" _find_dict_order_from_mock_obj_instantiation"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("except")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        dict_order "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Create a list of tuples from __dict__ in the order of instantiation")]),t._v("\n    _ordered_dict "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("d"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" d "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" dict_order"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" _ordered_dict\n\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("_find_dict_order_from_mock_obj_instantiation")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    dict_order "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Subclass the object’s class and define a __setattr__ method")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# to capture the attribute names as they are instantiated.")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("sub")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token builtin"}},[t._v("type")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__setattr__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            dict_order"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("key"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" value\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Inspect the __init__ method of the target class for arguments to be passed")]),t._v("\n    f "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__class__"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__\n    argspec "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" inspect"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getargspec"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    args_to_pass "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" argspec"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("args"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Run a dummy initialisation of the mock object.")]),t._v("\n    sub"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("*")]),t._v("args_to_pass"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" dict_order\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Problem: Class "),s("strong",[this._v("init")]),this._v(" method must only do simple attribute assignment")])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[this._v("This works primarily because the model objects don’t do anything complicated in the "),s("strong",[this._v("init")]),this._v(" method (which is good practice). They simply instantiate fields with default values. Any use of expressions involving constructor args would likely put a spanner in the works, particularly for non-string attributes.")])},function(){var t=this.$createElement,s=this._self._c||t;return s("h3",{attrs:{id:"option-3-explicit-order-definition"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#option-3-explicit-order-definition","aria-hidden":"true"}},[this._v("#")]),this._v(" Option 3: Explicit order definition")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Example of explicit serialization ordering in Address model class")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("Address")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token triple-quoted-string string"}},[t._v('""" Definition of the Address record type in EsrGo data files """')]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("*")]),t._v("args"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ModelBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Id "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("EffectiveDate "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" bot\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("EffectiveEndDate "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" eot\n        … "),a("span",{attrs:{class:"token operator"}},[t._v("<<")]),t._v(" More attributes initialized here "),a("span",{attrs:{class:"token operator"}},[t._v(">>")]),t._v("\n\n    @"),a("span",{attrs:{class:"token builtin"}},[t._v("property")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("sorted_for_json")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token string"}},[t._v("'Id'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'EffectiveDate'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'EffectiveEndDate'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'PersonId'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{attrs:{class:"token string"}},[t._v("'AddressType'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'AddressStyle'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'PrimaryFlag'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'AddressFirstLine'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{attrs:{class:"token string"}},[t._v("'AddressSecondLine'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'AddressThirdLine'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'AddressTown'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{attrs:{class:"token string"}},[t._v("'AddressCounty'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'AddressPostcode'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'AddressCountry'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{attrs:{class:"token string"}},[t._v("'LastUpdateDate'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'StateValue'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'TransportLineNo'")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("ordered_dict property of "),s("code",[this._v("ModelBase.py")])])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("ModelBase")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("AttrDisplay"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metaclass"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("ABCMeta"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    @"),a("span",{attrs:{class:"token builtin"}},[t._v("property")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("ordered_dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" collections "),a("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" OrderedDict\n        d "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" OrderedDict"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" a "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_for_json"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("try")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                d"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("a"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("getattr")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("except")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" d\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Problem with Option 3: Changes to attributes need to be handled in two places")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("TestModelSortedForJson")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unittest"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TestCase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("object_sorted_json_list_contains_all_attributes")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("not")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("callable")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token builtin"}},[t._v("getattr")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'sorted_for_json'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("raise")]),t._v(" NotImplementedError"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v('"sorted_for_json"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        attributes "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("sorted")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__dict__"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        json_sorted "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("sorted")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("obj"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_for_json"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" attributes "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" json_sorted\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("test01_address_json_sortorder_contains_all_attributes")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        address "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Address"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("assertTrue"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("object_sorted_json_list_contains_all_attributes"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("address"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("h2",{attrs:{id:"option-4-using-descriptors-to-help-define-attribute-ordering"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#option-4-using-descriptors-to-help-define-attribute-ordering","aria-hidden":"true"}},[this._v("#")]),this._v(" Option 4: Using Descriptors to help define attribute ordering")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[this._v("To use them in the context of recording attribute ordering, we define attributes at the class level using descriptors, rather than the usual way of assigning properties of self in the "),s("strong",[this._v("init")]),this._v(" method.")])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Use of descriptors to define model class attributes")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("Address")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# The metaclass will record the name and order of these class  attributes.")]),t._v("\n    Id "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" IntDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    EffectiveDate "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" DateDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    EffectiveEndDate "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" EndDateDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    PersonId "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" IntDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    AddressFirstLine "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" StringDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    AddressSecondLine "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" StringDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    AddressThirdLine "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" StringDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    AddressTown "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" StringDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    AddressCounty "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" StringDescriptor"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("*")]),t._v("args"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("**")]),t._v("kwargs"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ModelBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token comment"}},[t._v("# Instantiate instance attributes here with default values")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" d "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_descriptors"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token builtin"}},[t._v("setattr")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" d"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attribute_name"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" d"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("default"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Metaclass to process the model class descriptors")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("ModelMetaclass")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token builtin"}},[t._v("type")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__new__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cls"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bases"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" attrs"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        descriptors "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        order "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v("\n        "),a("span",{attrs:{class:"token comment"}},[t._v("# The metaclass scans the class attributes for descriptors")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" n"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" attrs"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                v"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attribute_name "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" n\n                v"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("instantiation_order "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" order\n                order "),a("span",{attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1")]),t._v("\n                descriptors"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token comment"}},[t._v("# Remove the descriptors as they interfere with SqlAlchemy Instrumentation")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" d "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" descriptors"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            attrs"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pop"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attribute_name"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token comment"}},[t._v("# Create the class instance and add the descriptors as a list")]),t._v("\n        cls_instance "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelMetaclass"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cls"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                       "),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__new__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cls"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bases"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" attrs"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        cls_instance"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_descriptors "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" descriptors\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" cls_instance\n")])])])},function(){var t=this.$createElement,s=this._self._c||t;return s("p",[s("strong",[this._v("Model descriptors and base class")])])},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" abc "),a("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ABCMeta\n"),a("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" decimal "),a("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Decimal\n"),a("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" Utility"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("date_constants "),a("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" bot"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" eot"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bot_datetime\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("ModelDescriptorBase")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("metaclass"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("ABCMeta"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attribute_name "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("default "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" default\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("instantiation_order "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__get__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" instance"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" owner"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__set__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" instance"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__repr__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"{}, order: {}, default: {}, descriptor: {}"')]),t._v("\\\n            "),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("format")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("attribute_name"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("instantiation_order"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("default"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{attrs:{class:"token builtin"}},[t._v("type")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__name__"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("DecimalDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("Decimal"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0.0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("IntDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("StringDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token string"}},[t._v("''")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("BoolDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("False")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("DateDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("bot"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("EndDateDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("eot"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("DateTimeDescriptor")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ModelDescriptorBase"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token builtin"}},[t._v("super")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__init__"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("default"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("bot_datetime"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])}],!1,null,null,null);e.options.__file="serializing-objects.md";s.default=e.exports}}]);